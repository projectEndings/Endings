Archiving. Now it's built, how do we archive it? Negotiating with the Library. The issue with URLs -- is a domain name intrinsic to the identity of the project? Will the archive [pay to] maintain it?

## 7. Archiving

The importance of secure archival storage has long been recognized, especially in the library community. Back in 2002, Alemneh et al. noted that "It is now common knowledge that digital information is fragile in ways that differ from traditional technologies, such as paper or microfilm. The fact that information is increasingly stored in digital form,[sic] has led to an accelerated search for effective methods of managing electronic information resources." However, the very title of that article, "A Metadata Approach to Preservation of Digital Resources," underscores the fact that for librarians, archiving is primarily a matter of metadata; "creation of preservation metadata for electronic files and digital collections are among the most important steps." The assumption has been that digital resources are discrete blobs to be stored in large repositories; accessibility and findability is a matter of the provision of effective descriptive metadata. Libraries have traditionally viewed digital archiving as a storage and replication issue; "in order to ensure longevity, the library will make multiple copies of our digital collections, aggregate them into Archival Information Packages (AIPs), and distribute these archival copies in offsite locations" (Goddard and Seeman 2020).

For end-users not able to access archiving services from libraries or similar institutions, there are also archiving services available on the Web, such as Zenodo (offered by CERN, https://zenodo.org/), Preprints.org, or HAL (https://hal.archives-ouvertes.fr/). All of these, however, follow a similar model: a single binary object such as an article is uploaded and associated with metadata. Datasets may also be attached, but these are viewed as objects to download. This kind of archiving, while it may be a useful backup strategy (and we can never have enough of those), will not make a digital edition project (i.e. a complex website) available in the way a user would want to access it: as a functioning website. The Text Encoding Initiative, for example, archives each version of its standards package, consisting of schemas, exemplars and other documentation, on Zenodo, but the end user can only download a zipped package of materials; they cannot browse and read the TEI Guidelines itself, as they can on the TEI's own website.

So when we think about archiving large digital edition projects, this sort of archiving really serves only one component of our needs: reliable backup. Of course we should not underestimate the importance of backup. But as we have suggested above, if a digital edition is to remain relevant, to be read and cited, and to hold its place in the scholarly dialogue, it must be fully functional, available, and usable. Saachi (2015), based on a now-inaccessible technical report from the National Archives of Australia, characterizes this kind of accessibility to digital objects as "performance" (51ff), and contrasts it with "stable artefacts". Interaction with digital resources in the performance mode is always a unique experience bound to a specific occasion, and is contingent on the availability of hardware and software components which are transient. "The NAA Performance Model explicitly addresses the need for something concrete that needs to experienced by a researcher in order access the essence of a record: a performance" (53). 

From an Endings perspective, then, although it is essential to be able to preserve the "stable artefact" in the form of an archive such as a zip file with associated metadata, preserving the "essence" of a digital edition really lies in maintaining its functionality so that users can experience it through "performance", or interaction. 

Of course librarians and archivists are already beginning to focus on this important distinction. The University of Victoria Library is in the process of developing a "Donation policy for legacy websites," which attempts to lay out the conditions under which an individual or a project group may transfer an entire website to the library for long-term storage, with the expectation that it will actually remain accessible as a website on the Internet for public access. Offering such a service is not simple, though. A library presented with a Tamagotchi-style web application, with dependencies on back-end databases and server-side scripting, will (and should, quite rightly) reject the "donation," which would actually amount to the passing on of technical debt and incessant maintenance. But the static site model we have proposed and implemented is not subject to these considerations. Assuming any functional webserver is available, a static site can be served for the foreseeable future with no maintenance burden whatsoever; only bandwidth and disk storage are required, just as is the case for binary-blob digital assets in the traditional archive model. 








