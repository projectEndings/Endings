## Why we need it?

In designing staticSearch, we had a number of considerations:

1. Sustainability: Searching is an essential part of our projects and so we needed a solution that we felt confident could persist in the long-term. As we have discussed in various venues, the problem of sustainability looms over the digital humanities with authors, editors, publishers, and stewards of digital documents continuing to face problems of sustainability, persistence, and archivability. 
2. Scalability: Digital Humanities project take a variety of forms; while some are quite small and focused (i.e. a single digital edition of a single text), the majority of the projects supported by our institutions are made up of large linked datasets, which, when converted to static HTML pages, yield tens of thousands of individual HTML documents, all of which ought to be searchable
3. Flexibility and Portability: Search is ubiquitious and most, if not all, of our projects are built with the assumption that there will be some sort of searching ability available in the future; much of our encoding work is predicated on the notion that good, clean encoding produces not only better texts, but ones more amenable to complex and specific querying in the future. Part of our goal was to make this kind of searching possible for projects and facilitate surfacing the scholarly work that goes into encoding these projects without resorting to bespoke solutions for each project. Of course, different projects inevitably require highly specific filters and facets for their research and so a search engine needed to be amenable to answering the various kinds of questions that digital humanities project ask.

Given the popularity of static web applications, there have been a number of solutions across industry and the digital humanities for integrating search within a static web application, which can broadly grouped into three categories. While we detail this in Holmes and Takeda 2019b, it is worth summarizing.

First, there are the tightly integrated self-hosted server-side approaches, like eXist or Solr, that are highly popular and effective, but are precisely the kinds of technologies that we sought to distance ourselves from via the Endings project. The second are API-driven, cloud-based search engines, like Elastisearch and Algolia. These services maintain the search indexes off-site. Of course, the most popular of these is Google Custom Search Engine (CSE), which Brian Rinaldi, in his guide to Static Site Genertors for O'Reilly, calls  "the undisputed king of search" and the "the best option" for those looking to integrate search into their static sites. Not only are we wary of Google CSE for a suite of non-technical reasons, we are also wary of it due to its severe limitations; while Google CSE can be tuned (to an extent) for an individual site, our projects—which are often large and complex textual collections—require highly specific filters and facets. While Algolia and ElastiSearch are far more tunable, they add a significant third-party dependency and require that projects incur additional monetary and technical costs. The third are frameworks that, like staticSearch, index the entire document collection during a build process. This third type, like Lunr, appear the most promising, but most are ill-equipped for handling large, complex document collections as their indexes are constructed at the document and collection level. 

Moreover existing Python or JavaScript implementations of stemmers, indexers, and tokenizers could not be easily integrated into our XML-based processing pipelines; of course, one can graft these technologies on to existing builds, but doing so adds significant complexity that, as we discovered, was unnecessary.   As Kraetke and Imsieske note, XSLT is a "modern, powerful static website generator"; with XSLT 3, the power of XSLT for static website generation is extended considerably thanks to built-in handling for the manipulation and creation of JSON.
